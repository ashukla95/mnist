{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv2D, MaxPool2D, GlobalAvgPool2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.applications import ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"train.csv\")\n",
    "test_df = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_df[\"label\"].values\n",
    "x_train = train_df[train_df.keys().drop([\"label\"])].values.reshape(-1,28,28,1)\n",
    "x_train = x_train/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test_df.values\n",
    "test = test/255\n",
    "test = test.reshape(-1, 28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x202516e97c8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[0][:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 64)        1664      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 28, 28, 64)        102464    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 14, 14, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 14, 14, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 14, 14, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 14, 14, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 7, 7, 64)          36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 7, 7, 64)          256       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               803072    \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 1,022,858\n",
      "Trainable params: 1,021,706\n",
      "Non-trainable params: 1,152\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model = Sequential()\n",
    "# model.add(Conv2D(filters=32, kernel_size=(5,5), input_shape=(28,28,1), activation=\"relu\", padding=\"Same\"))\n",
    "# model.add(Conv2D(filters=32, kernel_size=(5,5), activation=\"relu\", padding=\"Same\"))\n",
    "# model.add(Conv2D(filters=64, kernel_size=(3,3), activation=\"relu\", padding=\"Same\"))\n",
    "# model.add(Conv2D(filters=64, kernel_size=(3,3), activation=\"relu\", padding=\"Same\"))\n",
    "# model.add(MaxPool2D(pool_size=(2,2)))\n",
    "# model.add(Dropout(0.25))\n",
    "\n",
    "# model.add(Conv2D(filters=128, kernel_size=(3,3), activation=\"relu\", padding=\"Same\"))\n",
    "# model.add(Conv2D(filters=128, kernel_size=(3,3), activation=\"relu\", padding=\"Same\"))\n",
    "# model.add(MaxPool2D(pool_size=(2,2)))\n",
    "# model.add(Dropout(0.25))\n",
    "\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(256, activation=\"relu\"))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Dense(10, activation=\"softmax\"))\n",
    "# model.summary()\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters = 64, kernel_size = (5,5),padding = 'Same', activation ='relu', input_shape = (28,28,1)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(filters = 64, kernel_size = (5,5),padding = 'Same', activation ='relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', activation ='relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', activation ='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3,3), padding = 'Same',  activation ='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation = \"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Dense(10, activation = \"softmax\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "igen = ImageDataGenerator(\n",
    "    rotation_range=8,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1\n",
    ")\n",
    "igen.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = ReduceLROnPlateau(min_lr=0.00001, patience=3, verbose=1, factor=0.5, monitor=\"val_accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      " - 11s - loss: 0.0172 - accuracy: 0.9949 - val_loss: 0.0186 - val_accuracy: 0.9950\n",
      "Epoch 2/50\n",
      " - 10s - loss: 0.0161 - accuracy: 0.9953 - val_loss: 0.0209 - val_accuracy: 0.9942\n",
      "Epoch 3/50\n",
      " - 10s - loss: 0.0161 - accuracy: 0.9950 - val_loss: 0.0153 - val_accuracy: 0.9954\n",
      "Epoch 4/50\n",
      " - 10s - loss: 0.0158 - accuracy: 0.9957 - val_loss: 0.0169 - val_accuracy: 0.9949\n",
      "Epoch 5/50\n",
      " - 10s - loss: 0.0159 - accuracy: 0.9952 - val_loss: 0.0157 - val_accuracy: 0.9950\n",
      "Epoch 6/50\n",
      " - 10s - loss: 0.0128 - accuracy: 0.9963 - val_loss: 0.0139 - val_accuracy: 0.9956\n",
      "Epoch 7/50\n",
      " - 11s - loss: 0.0142 - accuracy: 0.9956 - val_loss: 0.0159 - val_accuracy: 0.9954\n",
      "Epoch 8/50\n",
      " - 11s - loss: 0.0128 - accuracy: 0.9960 - val_loss: 0.0155 - val_accuracy: 0.9957\n",
      "Epoch 9/50\n",
      " - 11s - loss: 0.0128 - accuracy: 0.9959 - val_loss: 0.0162 - val_accuracy: 0.9958\n",
      "Epoch 10/50\n",
      " - 11s - loss: 0.0127 - accuracy: 0.9963 - val_loss: 0.0173 - val_accuracy: 0.9950\n",
      "Epoch 11/50\n",
      " - 11s - loss: 0.0117 - accuracy: 0.9966 - val_loss: 0.0158 - val_accuracy: 0.9949\n",
      "Epoch 12/50\n",
      " - 11s - loss: 0.0112 - accuracy: 0.9970 - val_loss: 0.0176 - val_accuracy: 0.9949\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 13/50\n",
      " - 11s - loss: 0.0105 - accuracy: 0.9970 - val_loss: 0.0150 - val_accuracy: 0.9963\n",
      "Epoch 14/50\n",
      " - 11s - loss: 0.0097 - accuracy: 0.9975 - val_loss: 0.0168 - val_accuracy: 0.9957\n",
      "Epoch 15/50\n",
      " - 11s - loss: 0.0094 - accuracy: 0.9970 - val_loss: 0.0141 - val_accuracy: 0.9963\n",
      "Epoch 16/50\n",
      " - 11s - loss: 0.0078 - accuracy: 0.9976 - val_loss: 0.0162 - val_accuracy: 0.9954\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 17/50\n",
      " - 11s - loss: 0.0070 - accuracy: 0.9980 - val_loss: 0.0152 - val_accuracy: 0.9960\n",
      "Epoch 18/50\n",
      " - 11s - loss: 0.0063 - accuracy: 0.9980 - val_loss: 0.0153 - val_accuracy: 0.9962\n",
      "Epoch 19/50\n",
      " - 11s - loss: 0.0065 - accuracy: 0.9979 - val_loss: 0.0148 - val_accuracy: 0.9960\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 20/50\n",
      " - 11s - loss: 0.0069 - accuracy: 0.9981 - val_loss: 0.0148 - val_accuracy: 0.9958\n",
      "Epoch 21/50\n",
      " - 12s - loss: 0.0066 - accuracy: 0.9981 - val_loss: 0.0150 - val_accuracy: 0.9956\n",
      "Epoch 22/50\n",
      " - 11s - loss: 0.0051 - accuracy: 0.9984 - val_loss: 0.0144 - val_accuracy: 0.9960\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 23/50\n",
      " - 11s - loss: 0.0057 - accuracy: 0.9978 - val_loss: 0.0149 - val_accuracy: 0.9960\n",
      "Epoch 24/50\n",
      " - 11s - loss: 0.0052 - accuracy: 0.9984 - val_loss: 0.0149 - val_accuracy: 0.9958\n",
      "Epoch 25/50\n",
      " - 11s - loss: 0.0063 - accuracy: 0.9985 - val_loss: 0.0150 - val_accuracy: 0.9960\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 26/50\n",
      " - 11s - loss: 0.0048 - accuracy: 0.9987 - val_loss: 0.0148 - val_accuracy: 0.9960\n",
      "Epoch 27/50\n",
      " - 11s - loss: 0.0056 - accuracy: 0.9984 - val_loss: 0.0149 - val_accuracy: 0.9958\n",
      "Epoch 28/50\n",
      " - 11s - loss: 0.0051 - accuracy: 0.9981 - val_loss: 0.0150 - val_accuracy: 0.9960\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 29/50\n",
      " - 11s - loss: 0.0051 - accuracy: 0.9986 - val_loss: 0.0149 - val_accuracy: 0.9960\n",
      "Epoch 30/50\n",
      " - 11s - loss: 0.0055 - accuracy: 0.9984 - val_loss: 0.0148 - val_accuracy: 0.9960\n",
      "Epoch 31/50\n",
      " - 11s - loss: 0.0052 - accuracy: 0.9984 - val_loss: 0.0148 - val_accuracy: 0.9960\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "Epoch 32/50\n",
      " - 11s - loss: 0.0054 - accuracy: 0.9983 - val_loss: 0.0149 - val_accuracy: 0.9960\n",
      "Epoch 33/50\n",
      " - 11s - loss: 0.0057 - accuracy: 0.9981 - val_loss: 0.0149 - val_accuracy: 0.9958\n",
      "Epoch 34/50\n",
      " - 14s - loss: 0.0054 - accuracy: 0.9984 - val_loss: 0.0149 - val_accuracy: 0.9961\n",
      "Epoch 35/50\n",
      " - 14s - loss: 0.0045 - accuracy: 0.9987 - val_loss: 0.0149 - val_accuracy: 0.9960\n",
      "Epoch 36/50\n",
      " - 12s - loss: 0.0047 - accuracy: 0.9987 - val_loss: 0.0150 - val_accuracy: 0.9960\n",
      "Epoch 37/50\n",
      " - 11s - loss: 0.0057 - accuracy: 0.9984 - val_loss: 0.0150 - val_accuracy: 0.9960\n",
      "Epoch 38/50\n",
      " - 12s - loss: 0.0050 - accuracy: 0.9984 - val_loss: 0.0149 - val_accuracy: 0.9960\n",
      "Epoch 39/50\n",
      " - 11s - loss: 0.0041 - accuracy: 0.9985 - val_loss: 0.0150 - val_accuracy: 0.9960\n",
      "Epoch 40/50\n",
      " - 11s - loss: 0.0050 - accuracy: 0.9986 - val_loss: 0.0151 - val_accuracy: 0.9958\n",
      "Epoch 41/50\n",
      " - 11s - loss: 0.0051 - accuracy: 0.9986 - val_loss: 0.0151 - val_accuracy: 0.9958\n",
      "Epoch 42/50\n",
      " - 12s - loss: 0.0046 - accuracy: 0.9988 - val_loss: 0.0150 - val_accuracy: 0.9961\n",
      "Epoch 43/50\n",
      " - 11s - loss: 0.0054 - accuracy: 0.9984 - val_loss: 0.0150 - val_accuracy: 0.9958\n",
      "Epoch 44/50\n",
      " - 11s - loss: 0.0042 - accuracy: 0.9987 - val_loss: 0.0150 - val_accuracy: 0.9961\n",
      "Epoch 45/50\n",
      " - 11s - loss: 0.0066 - accuracy: 0.9980 - val_loss: 0.0151 - val_accuracy: 0.9960\n",
      "Epoch 46/50\n",
      " - 11s - loss: 0.0045 - accuracy: 0.9986 - val_loss: 0.0151 - val_accuracy: 0.9960\n",
      "Epoch 47/50\n",
      " - 11s - loss: 0.0055 - accuracy: 0.9984 - val_loss: 0.0151 - val_accuracy: 0.9958\n",
      "Epoch 48/50\n",
      " - 11s - loss: 0.0048 - accuracy: 0.9986 - val_loss: 0.0151 - val_accuracy: 0.9958\n",
      "Epoch 49/50\n",
      " - 11s - loss: 0.0046 - accuracy: 0.9984 - val_loss: 0.0151 - val_accuracy: 0.9960\n",
      "Epoch 50/50\n",
      " - 12s - loss: 0.0048 - accuracy: 0.9985 - val_loss: 0.0151 - val_accuracy: 0.9958\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x203b8b80f48>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(igen.flow(x_train, y_train, batch_size=128), epochs=50, validation_data=(x_val, y_val),\n",
    "         verbose = 2, steps_per_epoch=x_train.shape[0] // 128, callbacks=[lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = np.argmax(result, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 9, ..., 3, 9, 2], dtype=int64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv(\"sample_submission (1).csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub[\"Label\"] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv(\"try6.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
