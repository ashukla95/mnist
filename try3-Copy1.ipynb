{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv2D, MaxPool2D, GlobalAvgPool2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.applications import ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"train.csv\")\n",
    "test_df = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_df[\"label\"].values\n",
    "x_train = train_df[train_df.keys().drop([\"label\"])].values.reshape(-1,28,28,1)\n",
    "x_train = x_train/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test_df.values\n",
    "test = test/255\n",
    "test = test.reshape(-1, 28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x24beb937608>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[0][:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 64)        1664      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 28, 28, 64)        102464    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 14, 14, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 14, 14, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 14, 14, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 14, 14, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 7, 7, 64)          36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 7, 7, 64)          256       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               803072    \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 1,022,858\n",
      "Trainable params: 1,021,706\n",
      "Non-trainable params: 1,152\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model = Sequential()\n",
    "# model.add(Conv2D(filters=32, kernel_size=(5,5), input_shape=(28,28,1), activation=\"relu\", padding=\"Same\"))\n",
    "# model.add(Conv2D(filters=32, kernel_size=(5,5), activation=\"relu\", padding=\"Same\"))\n",
    "# model.add(Conv2D(filters=64, kernel_size=(3,3), activation=\"relu\", padding=\"Same\"))\n",
    "# model.add(Conv2D(filters=64, kernel_size=(3,3), activation=\"relu\", padding=\"Same\"))\n",
    "# model.add(MaxPool2D(pool_size=(2,2)))\n",
    "# model.add(Dropout(0.25))\n",
    "\n",
    "# model.add(Conv2D(filters=128, kernel_size=(3,3), activation=\"relu\", padding=\"Same\"))\n",
    "# model.add(Conv2D(filters=128, kernel_size=(3,3), activation=\"relu\", padding=\"Same\"))\n",
    "# model.add(MaxPool2D(pool_size=(2,2)))\n",
    "# model.add(Dropout(0.25))\n",
    "\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(256, activation=\"relu\"))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Dense(10, activation=\"softmax\"))\n",
    "# model.summary()\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters = 64, kernel_size = (5,5),padding = 'Same', activation ='relu', input_shape = (28,28,1)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(filters = 64, kernel_size = (5,5),padding = 'Same', activation ='relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', activation ='relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', activation ='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3,3), padding = 'Same',  activation ='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation = \"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Dense(10, activation = \"softmax\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "igen = ImageDataGenerator(\n",
    "    rotation_range=8,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1\n",
    ")\n",
    "igen.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = ReduceLROnPlateau(min_lr=0.00001, patience=3, verbose=1, factor=0.5, monitor=\"val_acc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      " - 39s - loss: 0.2783 - accuracy: 0.9127 - val_loss: 0.0715 - val_accuracy: 0.9783\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ashuk\\.conda\\envs\\tensorflow_env\\lib\\site-packages\\keras\\callbacks\\callbacks.py:1042: RuntimeWarning: Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: val_loss,val_accuracy,loss,accuracy,lr\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 39s - loss: 0.1203 - accuracy: 0.9630 - val_loss: 0.0421 - val_accuracy: 0.9858\n",
      "Epoch 3/20\n",
      " - 34s - loss: 0.0954 - accuracy: 0.9713 - val_loss: 0.0364 - val_accuracy: 0.9883\n",
      "Epoch 4/20\n",
      " - 33s - loss: 0.0886 - accuracy: 0.9733 - val_loss: 0.0450 - val_accuracy: 0.9852\n",
      "Epoch 5/20\n",
      " - 41s - loss: 0.0692 - accuracy: 0.9791 - val_loss: 0.0314 - val_accuracy: 0.9893\n",
      "Epoch 6/20\n",
      " - 43s - loss: 0.0682 - accuracy: 0.9805 - val_loss: 0.0235 - val_accuracy: 0.9923\n",
      "Epoch 7/20\n",
      " - 44s - loss: 0.0597 - accuracy: 0.9831 - val_loss: 0.0202 - val_accuracy: 0.9938\n",
      "Epoch 8/20\n",
      " - 37s - loss: 0.0552 - accuracy: 0.9840 - val_loss: 0.0204 - val_accuracy: 0.9938\n",
      "Epoch 9/20\n",
      " - 37s - loss: 0.0509 - accuracy: 0.9854 - val_loss: 0.0200 - val_accuracy: 0.9942\n",
      "Epoch 10/20\n",
      " - 38s - loss: 0.0487 - accuracy: 0.9861 - val_loss: 0.0294 - val_accuracy: 0.9904\n",
      "Epoch 11/20\n",
      " - 37s - loss: 0.0421 - accuracy: 0.9879 - val_loss: 0.0174 - val_accuracy: 0.9945\n",
      "Epoch 12/20\n",
      " - 37s - loss: 0.0414 - accuracy: 0.9872 - val_loss: 0.0164 - val_accuracy: 0.9952\n",
      "Epoch 13/20\n",
      " - 38s - loss: 0.0414 - accuracy: 0.9878 - val_loss: 0.0204 - val_accuracy: 0.9937\n",
      "Epoch 14/20\n",
      " - 41s - loss: 0.0403 - accuracy: 0.9886 - val_loss: 0.0149 - val_accuracy: 0.9951\n",
      "Epoch 15/20\n",
      " - 40s - loss: 0.0399 - accuracy: 0.9885 - val_loss: 0.0191 - val_accuracy: 0.9937\n",
      "Epoch 16/20\n",
      " - 38s - loss: 0.0359 - accuracy: 0.9895 - val_loss: 0.0148 - val_accuracy: 0.9945\n",
      "Epoch 17/20\n",
      " - 39s - loss: 0.0364 - accuracy: 0.9895 - val_loss: 0.0173 - val_accuracy: 0.9944\n",
      "Epoch 18/20\n",
      " - 37s - loss: 0.0346 - accuracy: 0.9891 - val_loss: 0.0194 - val_accuracy: 0.9940\n",
      "Epoch 19/20\n",
      " - 38s - loss: 0.0309 - accuracy: 0.9907 - val_loss: 0.0175 - val_accuracy: 0.9946\n",
      "Epoch 20/20\n",
      " - 44s - loss: 0.0316 - accuracy: 0.9909 - val_loss: 0.0170 - val_accuracy: 0.9939\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x24bc6184808>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(igen.flow(x_train, y_train, batch_size=16), epochs=20, validation_data=(x_val, y_val),\n",
    "         verbose = 2, steps_per_epoch=x_train.shape[0] // 16, callbacks=[lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = np.argmax(result, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 9, ..., 3, 9, 2], dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv(\"sample_submission (1).csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub[\"Label\"] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv(\"try4.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
